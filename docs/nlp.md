
## Natural language processing (NLP)

Natural language processing (NLP) is a field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora. Challenges in natural language processing frequently involve natural language understanding, natural language generation (frequently from formal, machine-readable logical forms), connecting language and machine perception, managing human-computer dialog systems, or some combination thereof.

## NLP Table words

| CoNLL        | Copora     | Chunking |
|--------------|------------|----------|
| Lemmatizing  | Stop words | tf–idf   |
| Tokenization |            |          |


## NLP Jargons

[CoNLL](http://www.conll.org/), the Conference on Natural Language Learning, is SIGNLL's(Special Interest Group on Natural Language Learning) yearly meeting.

More information available here http://www.signll.org/conll/

### Copora

NLTK is a massive toolkit for you. part of what they give you is a ton of highly valuable corpora to learn with, train against, and some of them are even capable of using in production.

About Copora //youtu.be/TKAXDqoG2dc

### Chunking
Chunking – Going up or down a level to change your perception.  Chunk up to a larger level of information; chunk down to be more specific. 

### Lemmatizing
A very similar operation to stemming is called lemmatizing. The major difference between these is, as you saw earlier, stemming can often create non-existent words.

So, your root stem, meaning the word you end up with, is not something you can just look up in a dictionary.

A root lemma, on the other hand, is a real word. Many times, you will wind up with a very similar word, but sometimes, you will wind up with a completely different word.

About Lemmatizing https://youtu.be/uoHVztKY6S4

### Stop words
Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query. 

### tf–idf

In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.[1] It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling.

Reference: https://en.wikipedia.org/wiki/Tf%E2%80%93idf

### Tokenization

Given a character sequence and a defined document unit, tokenization is the task of chopping it up into pieces, called tokens , perhaps at the same time throwing away certain characters, such as punctuation. Here is an example of tokenization:
